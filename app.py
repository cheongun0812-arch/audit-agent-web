import streamlit as st
import os
import google.generativeai as genai
from docx import Document
import PyPDF2
import time

# ==========================================
# 1. í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(
    page_title="AUDIT AI agent",
    page_icon="ğŸ›¡ï¸",
    layout="centered"
)

# ==========================================
# 2. ì‚¬ì´ë“œë°” (ë¡œê·¸ì¸ í¼)
# ==========================================
with st.sidebar:
    st.header("ğŸ” ë¡œê·¸ì¸")
    
    with st.form(key='login_form'):
        st.info("âš ï¸ ë³¸ì¸ì˜ API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n(ìµœì´ˆ 1íšŒ ì…ë ¥ í›„ 'ì €ì¥' ê¶Œì¥)")
        api_key_input = st.text_input("Google API Key", type="password")
        submit_button = st.form_submit_button(label="ì¸ì¦í•˜ê¸° âœ…")
    
    if submit_button:
        if api_key_input:
            try:
                genai.configure(api_key=api_key_input)
                st.session_state['api_key'] = api_key_input
                st.success("ì¸ì¦ ë˜ì—ˆìŠµë‹ˆë‹¤!")
            except:
                st.error("ì˜ëª»ëœ í‚¤ì…ë‹ˆë‹¤.")
        else:
            st.warning("í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
    elif 'api_key' in st.session_state:
        genai.configure(api_key=st.session_state['api_key'])
        st.success("ì¸ì¦ ìƒíƒœ ìœ ì§€ ì¤‘ âœ…")

    st.markdown("---")
    st.markdown("**[ëª¨ë°”ì¼ ì‚¬ìš© íŒ]**")
    st.markdown("1. í‚¤ ì…ë ¥ í›„ **[ì¸ì¦í•˜ê¸°]**")
    st.markdown("2. íŒì—… ëœ¨ë©´ **[ë¹„ë°€ë²ˆí˜¸ ì €ì¥]**")
    st.markdown("3. ë‹¤ìŒë¶€í„´ **ìë™ ì…ë ¥!**")

# ==========================================
# 3. ê¸°ëŠ¥ í•¨ìˆ˜ (í•µì‹¬ ì—…ê·¸ë ˆì´ë“œ: ëª¨ë¸ ìë™ ì°¾ê¸°)
# ==========================================

def get_model():
    # 1ìˆœìœ„ë¶€í„° 3ìˆœìœ„ê¹Œì§€ í›„ë³´êµ° ì„¤ì • (ìµœì‹  -> êµ¬í˜• ìˆœ)
    candidates = [
        'gemini-1.5-flash',      # ì†ë„ ìµœê°• (ëª¨ë°”ì¼ ì¶”ì²œ)
        'gemini-1.5-pro',        # ì„±ëŠ¥ ìµœê°•
        'models/gemini-1.5-flash',
        'models/gemini-pro'
    ]
    
    # 1. ëª©ë¡ ì¡°íšŒê°€ ê°€ëŠ¥í•˜ë©´ ì¡°íšŒí•´ì„œ ë§¤ì¹­
    try:
        my_models = [m.name for m in genai.list_models()]
        for candidate in candidates:
            # candidate ì´ë¦„ì´ my_models ì•ˆì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            for m in my_models:
                if candidate in m:
                    return genai.GenerativeModel(m)
    except:
        pass

    # 2. ì¡°íšŒ ì‹¤íŒ¨ ì‹œ, ê°€ì¥ í™•ë¥  ë†’ì€ ìµœì‹  ëª¨ë¸ ê°•ì œ ì§€ì •
    return genai.GenerativeModel('gemini-1.5-flash')

def read_file(uploaded_file):
    content = ""
    try:
        if uploaded_file.name.endswith('.txt'):
            content = uploaded_file.getvalue().decode("utf-8")
        elif uploaded_file.name.endswith('.pdf'):
            reader = PyPDF2.PdfReader(uploaded_file)
            for page in reader.pages: content += page.extract_text() + "\n"
        elif uploaded_file.name.endswith('.docx'):
            doc = Document(uploaded_file)
            content = "\n".join([para.text for para in doc.paragraphs])
    except Exception as e: return None
    return content

# ==========================================
# 4. ë©”ì¸ í™”ë©´
# ==========================================

st.title("ğŸ›¡ï¸ AUDIT AI agent")
st.markdown("### PCì™€ ëª¨ë°”ì¼ ì–´ë””ì„œë“  ì‰½ê³  ë¹ ë¥´ê²Œ!")

tab1, tab2 = st.tabs(["ğŸ“‘ ë¬¸ì„œ ê²€í† /ì‘ì„±", "ğŸ’¬ AI ê°ì‚¬ê´€ê³¼ ëŒ€í™”"])

# --- [Tab 1] ë¬¸ì„œ ê²€í†  ---
with tab1:
    option = st.selectbox(
        "ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”",
        ("1. âš–ï¸ ë²•ë¥  ë¦¬ìŠ¤í¬ ì •ë°€ ê²€í† ", "2. ğŸ“ ê°ì‚¬ ë³´ê³ ì„œ ì´ˆì•ˆ ì‘ì„±", "3. âœ¨ ì˜¤íƒ€ ìˆ˜ì • ë° ë¬¸êµ¬ êµì •", "4. ğŸ“‘ ê¸°ì•ˆë¬¸/ê³µë¬¸ ì´ˆì•ˆ ìƒì„±")
    )

    st.markdown("##### ğŸ“‚ ê²€í†  ëŒ€ìƒ(Target) íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("íŒŒì¼ ì„ íƒ (í° ë‚´ì¥ íŒŒì¼/ë‹¤ìš´ë¡œë“œí•¨)", type=['txt', 'pdf', 'docx'], key="target")

    with st.expander("ğŸ“š ì°¸ê³  ìë£Œ(Reference) í•¨ê»˜ ì˜¬ë¦¬ê¸° (ì„ íƒ)"):
        uploaded_refs = st.file_uploader("ê·œì •/ì§€ì¹¨ íŒŒì¼ ì—…ë¡œë“œ", type=['txt', 'pdf', 'docx'], accept_multiple_files=True)
        ref_content = ""
        if uploaded_refs:
            for ref_file in uploaded_refs:
                content = read_file(ref_file)
                if content: ref_content += content + "\n"

    if st.button("ğŸš€ AI ê²€í†  ì‹œì‘", use_container_width=True):
        if 'api_key' not in st.session_state:
            st.error("â›” ì™¼ìª½ ë©”ë‰´(>)ì—ì„œ [ì¸ì¦í•˜ê¸°]ë¥¼ ë¨¼ì € ì§„í–‰í•´ì£¼ì„¸ìš”.")
        elif not uploaded_file:
            st.warning("ê²€í† í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner('ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
                content = read_file(uploaded_file)
                if content:
                    final_ref = ref_content if ref_content else "ì¼ë°˜ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤/ë²•ë¥  í‘œì¤€ ë° ìƒì‹"
                    prompt = f"""
                    ë‹¹ì‹ ì€ ê°ì‚¬ì‹¤ ìˆ˜ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    [ì‘ì—… ëª¨ë“œ: {option}]
                    [ì°¸ê³  ìë£Œ: {final_ref}]
                    [ëŒ€ìƒ íŒŒì¼ ë‚´ìš©]
                    {content}
                    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ , ë³´ê³ ì„œë¡œ ì‘ì„±í•´ì¤˜.
                    """
                    try:
                        model = get_model()
                        response = model.generate_content(prompt)
                        st.success("ì™„ë£Œ!")
                        st.markdown(response.text)
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜: {e}")

# --- [Tab 2] ì±—ë´‡ ê¸°ëŠ¥ ---
with tab2:
    st.info("íŒŒì¼ ë‚´ìš©ì— ëŒ€í•´ ëŒ€í™”í•˜ë“¯ ë¬¼ì–´ë³´ì„¸ìš”.")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥..."):
        if 'api_key' not in st.session_state:
            st.error("API í‚¤ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                
                context = ""
                # Tab1ì—ì„œ ì˜¬ë¦° íŒŒì¼ì´ ìˆìœ¼ë©´ ì±—ë´‡ë„ ì•Œê²Œ í•¨
                if ref_content: context += f"[ì°¸ê³ ìë£Œ]\n{ref_content}\n"
                if uploaded_file: 
                    target_content = read_file(uploaded_file)
                    if target_content: context += f"[ê²€í† ëŒ€ìƒíŒŒì¼]\n{target_content}\n"
                
                final_prompt = f"{context}\n\nì§ˆë¬¸: {prompt}"
                
                try:
                    # [ì¤‘ìš”] ì—¬ê¸°ì„œ ì—…ê·¸ë ˆì´ë“œëœ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤
                    model = get_model()
                    response = model.generate_content(final_prompt)
                    message_placeholder.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
