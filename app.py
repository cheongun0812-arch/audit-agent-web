import streamlit as st
import os
import google.generativeai as genai
from docx import Document
import PyPDF2
import time

# ==========================================
# 1. í˜ì´ì§€ ì„¤ì •
# ==========================================
st.set_page_config(
    page_title="AUDIT AI agent",
    page_icon="ğŸ›¡ï¸",
    layout="centered"
)

# ==========================================
# 2. ì‚¬ì´ë“œë°” (ì„¤ì • ë° ì°¸ê³ ìë£Œ)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • ë° ìë£Œ")
    
    # 1. API í‚¤
    with st.expander("ğŸ” API í‚¤ ì„¤ì •", expanded=True):
        api_key_input = st.text_input("Google API Key", type="password", help="ë³¸ì¸ì˜ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        if api_key_input:
            try:
                genai.configure(api_key=api_key_input)
                st.success("ì¸ì¦ ì™„ë£Œ âœ…")
            except:
                st.error("ì˜ëª»ëœ í‚¤ì…ë‹ˆë‹¤.")
        else:
            st.warning("í‚¤ ì…ë ¥ í•„ìš”")

    st.markdown("---")
    
    # 2. [í•µì‹¬ ì—…ê·¸ë ˆì´ë“œ] ì°¸ê³  ìë£Œ ì—…ë¡œë“œ ê¸°ëŠ¥
    st.header("ğŸ“š ì°¸ê³  ìë£Œ(Reference)")
    st.info("ê²€í†  ê¸°ì¤€ì´ ë  ê·œì •/ì§€ì¹¨ íŒŒì¼ì„ ì—¬ê¸°ì— ì˜¬ë ¤ì£¼ì„¸ìš”.")
    uploaded_refs = st.file_uploader(
        "ê·œì •/ë§¤ë‰´ì–¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", 
        type=['txt', 'pdf', 'docx'], 
        accept_multiple_files=True
    )
    
    # ì°¸ê³  ìë£Œ í…ìŠ¤íŠ¸ ë³€í™˜
    ref_content = ""
    if uploaded_refs:
        for ref_file in uploaded_refs:
            if ref_file.name.endswith('.txt'):
                ref_content += ref_file.getvalue().decode("utf-8") + "\n"
            elif ref_file.name.endswith('.pdf'):
                pdf_reader = PyPDF2.PdfReader(ref_file)
                for page in pdf_reader.pages: ref_content += page.extract_text() + "\n"
            elif ref_file.name.endswith('.docx'):
                doc = Document(ref_file)
                ref_content += "\n".join([para.text for para in doc.paragraphs]) + "\n"
        st.success(f"{len(uploaded_refs)}ê°œì˜ ì°¸ê³  ìë£Œ ë¡œë“œ ì™„ë£Œ!")

# ==========================================
# 3. ê¸°ëŠ¥ í•¨ìˆ˜
# ==========================================
def get_model():
    return genai.GenerativeModel('gemini-pro')

def read_file(uploaded_file):
    content = ""
    try:
        if uploaded_file.name.endswith('.txt'):
            content = uploaded_file.getvalue().decode("utf-8")
        elif uploaded_file.name.endswith('.pdf'):
            reader = PyPDF2.PdfReader(uploaded_file)
            for page in reader.pages: content += page.extract_text() + "\n"
        elif uploaded_file.name.endswith('.docx'):
            doc = Document(uploaded_file)
            content = "\n".join([para.text for para in doc.paragraphs])
    except Exception as e: return None
    return content

# ==========================================
# 4. ë©”ì¸ í™”ë©´
# ==========================================

st.title("ğŸ›¡ï¸ AUDIT AI agent")
st.markdown("### PCì™€ ëª¨ë°”ì¼ ì–´ë””ì„œë“  ì‰½ê³  ë¹ ë¥´ê²Œ!")

# íƒ­ ë©”ë‰´ë¡œ ê¸°ëŠ¥ ë¶„ë¦¬
tab1, tab2 = st.tabs(["ğŸ“‘ ë¬¸ì„œ ê²€í† /ì‘ì„±", "ğŸ’¬ AI ê°ì‚¬ê´€ê³¼ ëŒ€í™”"])

# --- [Tab 1] ê¸°ì¡´ ë¬¸ì„œ ê²€í†  ê¸°ëŠ¥ ---
with tab1:
    option = st.selectbox(
        "ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”",
        ("1. âš–ï¸ ë²•ë¥  ë¦¬ìŠ¤í¬ ì •ë°€ ê²€í† ", "2. ğŸ“ ê°ì‚¬ ë³´ê³ ì„œ ì´ˆì•ˆ ì‘ì„±", "3. âœ¨ ì˜¤íƒ€ ìˆ˜ì • ë° ë¬¸êµ¬ êµì •", "4. ğŸ“‘ ê¸°ì•ˆë¬¸/ê³µë¬¸ ì´ˆì•ˆ ìƒì„±")
    )

    st.markdown("##### ğŸ“‚ ê²€í†  ëŒ€ìƒ(Target) íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ì—¬ê¸°ë¥¼ ëˆŒëŸ¬ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=['txt', 'pdf', 'docx'], key="target")

    if st.button("ğŸš€ AI ê²€í†  ì‹œì‘", use_container_width=True):
        if not api_key_input:
            st.error("ì‚¬ì´ë“œë°”ì— API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        if not uploaded_file:
            st.warning("ê²€í† í•  ëŒ€ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner('ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
                content = read_file(uploaded_file)
                if content:
                    # ì°¸ê³ ìë£Œê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ëª¨ë“œ
                    final_ref = ref_content if ref_content else "ì¼ë°˜ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤/ë²•ë¥  í‘œì¤€ ë° ìƒì‹"
                    
                    prompt = f"""
                    ë‹¹ì‹ ì€ ê°ì‚¬ì‹¤ ìˆ˜ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    [ì‘ì—… ëª¨ë“œ: {option}]
                    [ì°¸ê³  ìë£Œ(ê¸°ì¤€): {final_ref}]
                    [ëŒ€ìƒ íŒŒì¼ ë‚´ìš©]
                    {content}
                    
                    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ , ê°€ë…ì„± ì¢‹ì€ ë³´ê³ ì„œë¡œ ì‘ì„±í•´ì¤˜.
                    """
                    try:
                        model = get_model()
                        response = model.generate_content(prompt)
                        st.success("ì™„ë£Œ!")
                        st.markdown(response.text)
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜: {e}")

# --- [Tab 2] ì±—ë´‡ ê¸°ëŠ¥ (New!) ---
with tab2:
    st.info("íŒŒì¼ ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ëŒ€í™”í•˜ë“¯ ë¬¼ì–´ë³´ì„¸ìš”.")
    
    # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì´ ê³„ì•½ì„œì˜ ë…ì†Œì¡°í•­ì´ ë­ì•¼?)"):
        if not api_key_input:
            st.error("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # AI ë‹µë³€ ìƒì„±
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                
                # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì°¸ê³ ìë£Œ + ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆë‹¤ë©´ í¬í•¨)
                context = ""
                if ref_content: context += f"[ì°¸ê³ ìë£Œ]\n{ref_content}\n"
                # Tab1ì—ì„œ ì˜¬ë¦° íŒŒì¼ì´ ìˆë‹¤ë©´ ì±—ë´‡ë„ ê·¸ê±¸ ì•Œê²Œ í•¨
                if uploaded_file: 
                    target_content = read_file(uploaded_file)
                    if target_content: context += f"[ê²€í† ëŒ€ìƒíŒŒì¼]\n{target_content}\n"
                
                final_prompt = f"{context}\n\nì§ˆë¬¸: {prompt}"
                
                try:
                    model = get_model()
                    response = model.generate_content(final_prompt)
                    full_response = response.text
                    message_placeholder.markdown(full_response)
                    
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {e}")
